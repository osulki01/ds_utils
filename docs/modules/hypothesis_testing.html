

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ds_utils.hypothesis_testing &mdash; ds_utils 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ds_utils.sklearn_utils" href="sklearn_utils.html" />
    <link rel="prev" title="Welcome to ds_utils’s documentation!" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> ds_utils
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#contents">Contents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-big-should-my-sample-be">How Big Should My Sample Be?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-your-experimental-groups">Creating Your Experimental Groups</a></li>
<li class="toctree-l3"><a class="reference internal" href="#testing-for-significance">Testing For Significance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-overview">Module Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-ds_utils.hypothesis_testing.check_experiment_inputs">check_experiment_inputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-ds_utils.hypothesis_testing.evaluation">evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-ds_utils.hypothesis_testing.set_up_experiment">set_up_experiment</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sklearn_utils.html">Scikit-learn Utilities</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ds_utils</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>ds_utils.hypothesis_testing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/modules/hypothesis_testing.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ds-utils-hypothesis-testing">
<h1>ds_utils.hypothesis_testing<a class="headerlink" href="#ds-utils-hypothesis-testing" title="Permalink to this headline">¶</a></h1>
<p>Setting up and evaluating experiments.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Much of the underlying functionality in this module is handled by the excellent
<a class="reference external" href="https://www.statsmodels.org/stable/index.html">statsmodels</a> package.</p>
</div>
<div class="section" id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h2>
<div class="contents local topic" id="id1">
<ul class="simple">
<li><p><a class="reference internal" href="#how-big-should-my-sample-be" id="id2">How Big Should My Sample Be?</a></p></li>
<li><p><a class="reference internal" href="#creating-your-experimental-groups" id="id3">Creating Your Experimental Groups</a></p></li>
<li><p><a class="reference internal" href="#testing-for-significance" id="id4">Testing For Significance</a></p></li>
<li><p><a class="reference internal" href="#module-overview" id="id5">Module Overview</a></p></li>
<li><p><a class="reference internal" href="#submodules" id="id6">Submodules</a></p></li>
</ul>
</div>
<div class="section" id="how-big-should-my-sample-be">
<h3><a class="toc-backref" href="#id2">How Big Should My Sample Be?</a><a class="headerlink" href="#how-big-should-my-sample-be" title="Permalink to this headline">¶</a></h3>
<p>When designing an experiment, you will want to ensure you have a statistically significant sample. The online fashion
retailer Stitch Fix has written a terrific
<a class="reference external" href="https://multithreaded.stitchfix.com/blog/2015/05/26/significant-sample/">article</a> on the aspects that you should
consider.</p>
<p><a class="reference internal" href="#ds_utils.hypothesis_testing.set_up_experiment.calculate_required_sample_size" title="ds_utils.hypothesis_testing.set_up_experiment.calculate_required_sample_size"><code class="xref py py-func docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.set_up_experiment.calculate_required_sample_size()</span></code></a> is designed to help you express
these considerations and gain an indication of how big your sample size should be.</p>
<p>Firstly, you must identify what metric you are trying to change, and what a meaningful shift would represent. Often
this involves liaising with Commercial Finance colleagues or those who know the domain best, to attach a £ value to
changes in the metric and understand at what point the shift becomes worth pursuing.</p>
<p>Once you have gone through this process, you know what the values for <code class="xref py py-data docutils literal notranslate"><span class="pre">baseline_metric_value</span></code>,
<code class="xref py py-data docutils literal notranslate"><span class="pre">new_metric_value</span></code>, and <code class="xref py py-data docutils literal notranslate"><span class="pre">measurement_type</span></code> should be. The <code class="xref py py-data docutils literal notranslate"><span class="pre">measurement_type</span></code> is important
because whether you are measuring a mean or a percentage dictates what type of testing you will be using.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method makes calculations on the proviso that you will be using a z-test when measuring proportions, and a
t-test when measuring means. This involves the assumption that you will have at least 10 records that display the
positive and negative binary classes when it comes to a proportion, and that the data is normally distributed and we
do not know the true population standard deviation when it comes to means.</p>
<p>This <a class="reference external" href="https://bloomingtontutors.com/blog/when-to-use-the-z-test-versus-t-test">flow-chart</a> articulates the reasons
why particularly well.</p>
</div>
<p>For instance, you may have a web journey with a 50% conversion rate, and an increase to 55% would make it worthwhile
implementing the change you are testing.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ds_utils.hypothesis_testing</span> <span class="kn">import</span> <span class="n">set_up_experiment</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">suggested_sample_size</span> <span class="o">=</span> <span class="n">set_up_experiment</span><span class="o">.</span><span class="n">calculate_required_sample_size</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">baseline_metric_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">new_metric_value</span><span class="o">=</span><span class="mf">0.55</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">measurement_type</span><span class="o">=</span><span class="s1">&#39;proportion,</span>
<span class="gp">... </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">suggested_sample_size</span><span class="p">)</span>
<span class="go">1564</span>
</pre></div>
</div>
<p>In cases where you are measuring a mean, such as average spend per user, you will also need to know the standard
deviation in order to calculate your sample size. In this scenario, we know that users typically spend £10.25. If we
can increase that to £10.75 then we would be happy with the outcome, and we know from observing spend in recent periods
that the average spend has a standard deviation of £5.55.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ds_utils.hypothesis_testing</span> <span class="kn">import</span> <span class="n">set_up_experiment</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">suggested_sample_size</span> <span class="o">=</span> <span class="n">set_up_experiment</span><span class="o">.</span><span class="n">calculate_required_sample_size</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">baseline_metric_value</span><span class="o">=</span><span class="mf">10.25</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">new_metric_value</span><span class="o">=</span><span class="mf">10.75</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">measurement_type</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
<span class="hll"><span class="gp">... </span>    <span class="n">standard_deviation</span><span class="o">=</span><span class="mf">5.55</span><span class="p">,</span>
</span><span class="gp">... </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">suggested_sample_size</span><span class="p">)</span>
<span class="go">1935</span>
</pre></div>
</div>
<p>Depending on your experiment, you can also specify additional parameters:</p>
<ul class="simple">
<li><p>Whether your test is <a class="reference external" href="https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/">one-tailed/two-tailed</a>.
The default for <code class="xref py py-data docutils literal notranslate"><span class="pre">alternative_hypothesis</span></code> is ‘two-sided’ because we’re generally open to learning if the
metric worsens, not only if it improves.</p></li>
<li><p>The <a class="reference external" href="https://www.statisticsteacher.org/2017/09/15/what-is-power/">statistical power</a> i.e. the probability of
detecting a change if it does indeed exist. The default value for <code class="xref py py-data docutils literal notranslate"><span class="pre">power</span></code> is 0.8 but you should consider the
context of your experiment i.e. if there is a big risk associated with failing to detect a genuine effect, then you
may want to increase your power.</p></li>
<li><p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Statistical_significance">significance level</a> i.e. the false positive rate. Once
again, consider your context, and if there is a big risk associated with determining that a effect exists when it does
not, then you may want to reduce your <code class="xref py py-data docutils literal notranslate"><span class="pre">significance_level</span></code> from the default of 5%.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ds_utils.hypothesis_testing</span> <span class="kn">import</span> <span class="n">set_up_experiment</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">suggested_sample_size</span> <span class="o">=</span> <span class="n">set_up_experiment</span><span class="o">.</span><span class="n">calculate_required_sample_size</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">baseline_metric_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">new_metric_value</span><span class="o">=</span><span class="mf">0.55</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">measurement_type</span><span class="o">=</span><span class="s1">&#39;proportion&#39;</span><span class="p">,</span>
<span class="hll"><span class="gp">... </span>    <span class="n">alternative_hypothesis</span><span class="o">=</span><span class="s1">&#39;larger&#39;</span><span class="p">,</span>
</span><span class="hll"><span class="gp">... </span>    <span class="n">power</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
</span><span class="hll"><span class="gp">... </span>    <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
</span><span class="gp">... </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">suggested_sample_size</span><span class="p">)</span>
<span class="go">2594</span>
</pre></div>
</div>
</div>
<div class="section" id="creating-your-experimental-groups">
<h3><a class="toc-backref" href="#id3">Creating Your Experimental Groups</a><a class="headerlink" href="#creating-your-experimental-groups" title="Permalink to this headline">¶</a></h3>
<p>Once you know how big your sample sizes should be, you will need to create individual groups that will make up the
experiment.</p>
<p>The function <a class="reference internal" href="#ds_utils.hypothesis_testing.set_up_experiment.create_sample_groups" title="ds_utils.hypothesis_testing.set_up_experiment.create_sample_groups"><code class="xref py py-func docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.set_up_experiment.create_sample_groups()</span></code></a> allows you to randomly
assign records from a dataframe to distinct experimental groups.</p>
<p>Let’s assume we have a group of people where we know their eye colour; this won’t be used to separate them into sample
groups, but we may want to retain that information for the analysis, or checking that our sample groups have a similarly
representative distribution.</p>
<p>This is our starting dataset, which will have an additional column appended to the end showing the experimental group
that each row will belong to.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">ds_utils.hypothesis_testing</span> <span class="kn">import</span> <span class="n">set_up_experiment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">population_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;eye_colour&#39;</span><span class="p">],</span>
<span class="gp">... </span>                             <span class="n">data</span><span class="o">=</span><span class="p">[[</span><span class="mi">86</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">],</span>
<span class="gp">... </span>                                   <span class="p">[</span><span class="mi">54</span><span class="p">,</span> <span class="s1">&#39;brown&#39;</span><span class="p">],</span>
<span class="gp">... </span>                                   <span class="p">[</span><span class="mi">31</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">],</span>
<span class="gp">... </span>                                   <span class="p">[</span><span class="mi">95</span><span class="p">,</span> <span class="s1">&#39;hazel&#39;</span><span class="p">]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">population_df</span>

<span class="go">   user_id   eye_colour</span>
<span class="go">0       86         blue</span>
<span class="go">1       54        brown</span>
<span class="go">2       31        green</span>
<span class="go">3       95        hazel</span>
</pre></div>
</div>
<p>You can evenly split your dataframe by simply providing a list of names for each of your sample groups.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sample_groups_df</span> <span class="o">=</span> <span class="n">set_up_experiment</span><span class="o">.</span><span class="n">create_sample_groups</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">original_population</span><span class="o">=</span><span class="n">population_df</span><span class="p">,</span>
<span class="hll"><span class="gp">&gt;&gt;&gt; </span>    <span class="n">sample_groups</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Group 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Group 2&#39;</span><span class="p">],</span>
</span><span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">sample_groups_df</span>

<span class="go">      user_id   eye_colour   sample_group</span>
<span class="go">0       86            blue        Group 1</span>
<span class="go">1       54           brown        Group 2</span>
<span class="go">2       31           green        Group 2</span>
<span class="go">3       95           hazel        Group 1</span>
</pre></div>
</div>
<p>Alternatively, you can specify the number of records you want to assign to each group. If your sizes do not cover the
entire population, then the method will only return the records which were assigned to a sample group.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sample_groups_df</span> <span class="o">=</span> <span class="n">set_up_experiment</span><span class="o">.</span><span class="n">create_sample_groups</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">original_population</span><span class="o">=</span><span class="n">population_df</span><span class="p">,</span>
<span class="hll"><span class="gp">&gt;&gt;&gt; </span>    <span class="n">sample_groups</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Group 1&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Group 2&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
</span><span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">sample_groups_df</span>

<span class="go">      user_id   eye_colour   sample_group</span>
<span class="go">0       86            blue        Group 1</span>
<span class="go">2       31           green        Group 2</span>
<span class="go">3       95           hazel        Group 1</span>
</pre></div>
</div>
<p>Or finally, you can specify the proportion of rows that should be assigned to each group. Once again, if your
proportions do not cover the entire population, then the method will only return the records which were assigned to a
sample group.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sample_groups_df</span> <span class="o">=</span> <span class="n">set_up_experiment</span><span class="o">.</span><span class="n">create_sample_groups</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">original_population</span><span class="o">=</span><span class="n">population_df</span><span class="p">,</span>
<span class="hll"><span class="gp">&gt;&gt;&gt; </span>    <span class="n">sample_groups</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Group 1&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;Group 2&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;Group 3&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
</span><span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">sample_groups_df</span>

<span class="go">      user_id   eye_colour   sample_group</span>
<span class="go">0       86            blue        Group 2</span>
<span class="go">1       54           brown        Group 3</span>
<span class="go">2       31           green        Group 1</span>
<span class="go">3       95           hazel        Group 1</span>
</pre></div>
</div>
</div>
<div class="section" id="testing-for-significance">
<h3><a class="toc-backref" href="#id4">Testing For Significance</a><a class="headerlink" href="#testing-for-significance" title="Permalink to this headline">¶</a></h3>
<p>When your experiment has run and you have some results to analyse, use
<a class="reference internal" href="#module-ds_utils.hypothesis_testing.evaluation" title="ds_utils.hypothesis_testing.evaluation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.evaluation</span></code></a> to test for significance.</p>
<p>In cases where you have values for each observation in the experiment,
<a class="reference internal" href="#ds_utils.hypothesis_testing.evaluation.parametric_significance_test_on_raw_observations" title="ds_utils.hypothesis_testing.evaluation.parametric_significance_test_on_raw_observations"><code class="xref py py-func docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.evaluation.parametric_significance_test_on_raw_observations()</span></code></a> can be used.</p>
</div>
<div class="section" id="module-overview">
<h3><a class="toc-backref" href="#id5">Module Overview</a><a class="headerlink" href="#module-overview" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#module-ds_utils.hypothesis_testing.check_experiment_inputs" title="ds_utils.hypothesis_testing.check_experiment_inputs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.check_experiment_inputs</span></code></a></p></td>
<td><p>Internal checks within the package to ensure that the parameters provided when setting up or evaluating an experiment are valid.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#module-ds_utils.hypothesis_testing.evaluation" title="ds_utils.hypothesis_testing.evaluation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.evaluation</span></code></a></p></td>
<td><p>Analyse the outcome of an experiment and test for significance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#module-ds_utils.hypothesis_testing.set_up_experiment" title="ds_utils.hypothesis_testing.set_up_experiment"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ds_utils.hypothesis_testing.set_up_experiment</span></code></a></p></td>
<td><p>Helper functions when setting up an experiment.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="submodules">
<h3><a class="toc-backref" href="#id6">Submodules</a><a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h3>
<div class="section" id="module-ds_utils.hypothesis_testing.check_experiment_inputs">
<span id="check-experiment-inputs"></span><h4>check_experiment_inputs<a class="headerlink" href="#module-ds_utils.hypothesis_testing.check_experiment_inputs" title="Permalink to this headline">¶</a></h4>
<p>Internal checks within the package to ensure that the parameters provided when setting up or evaluating an experiment are
valid.</p>
<dl class="py function">
<dt id="ds_utils.hypothesis_testing.check_experiment_inputs.check_if_sample_sizes_are_proportions_or_absolute">
<code class="sig-name descname">check_if_sample_sizes_are_proportions_or_absolute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample_groups</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>Union<span class="p">[</span>float<span class="p">, </span>int<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; str<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/check_experiment_inputs.html#check_if_sample_sizes_are_proportions_or_absolute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.check_experiment_inputs.check_if_sample_sizes_are_proportions_or_absolute" title="Permalink to this definition">¶</a></dt>
<dd><p>Identifies whether the user has specified the size of each sample group as a proportion of the population, or their
absolute size in terms of number of records.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sample_groups</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>] or </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – Keys: The names of each sample group
Values: How big they should be.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Whether the sizes reflect ‘proportion’ or their ‘absolute’ size.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the values provided for the sizes of each sample group are not all floats (proportions), or all integers
    (absolute sizes).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ds_utils.hypothesis_testing.check_experiment_inputs.validate_binary_events_are_represented_with_0_or_1">
<code class="sig-name descname">validate_binary_events_are_represented_with_0_or_1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_observations</span><span class="p">:</span> <span class="n">numpy.ndarray</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/check_experiment_inputs.html#validate_binary_events_are_represented_with_0_or_1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.check_experiment_inputs.validate_binary_events_are_represented_with_0_or_1" title="Permalink to this definition">¶</a></dt>
<dd><p>When the experiment is evaluating whether a proportion has changed, the raw observations should be encoded as
0 (non-event) or 1 (event).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>experiment_observations</strong> (<em>numpy array_like</em>) – Observations for specific group in the experiment.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the observations are not all represented by 0’s and 1’s only.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ds_utils.hypothesis_testing.check_experiment_inputs.validate_experiment_parameter_between_0_and_1">
<code class="sig-name descname">validate_experiment_parameter_between_0_and_1</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">parameter_value</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">experiment_parameter</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/check_experiment_inputs.html#validate_experiment_parameter_between_0_and_1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.check_experiment_inputs.validate_experiment_parameter_between_0_and_1" title="Permalink to this definition">¶</a></dt>
<dd><p>Raises exception if a parameter for the experiment e.g. power, or significance level is not in the correct range
0 &lt; parameter_value &lt; 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameter_value</strong> – Value provided for the parameter e.g. 0.05 to represent a 5% significance level.</p></li>
<li><p><strong>experiment_parameter</strong> – What type of parameter has been provided e.g. ‘significance_level’ / ‘power’ / ‘sample_size_proportions’.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If 0 &lt; parameter_value &lt; 1 not satisfied.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ds_utils.hypothesis_testing.check_experiment_inputs.validate_measurement_type_is_valid">
<code class="sig-name descname">validate_measurement_type_is_valid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">measurement_type</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/check_experiment_inputs.html#validate_measurement_type_is_valid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.check_experiment_inputs.validate_measurement_type_is_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the experiment has been correctly specified as measuring proportions or means.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>measurement_type</strong> (<em>str</em>) – What type of metric the experiment is measuring i.e. proportion (e.g. % conversion rate) or mean (e.g. average
spend).</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If <cite>measurement_type</cite> not in [‘proportion’, ‘mean’].</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ds_utils.hypothesis_testing.check_experiment_inputs.validate_sample_size_values_are_appropriate">
<code class="sig-name descname">validate_sample_size_values_are_appropriate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">original_population</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sample_groups</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>Union<span class="p">[</span>float<span class="p">, </span>int<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">size_type</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/check_experiment_inputs.html#validate_sample_size_values_are_appropriate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.check_experiment_inputs.validate_sample_size_values_are_appropriate" title="Permalink to this definition">¶</a></dt>
<dd><p>When creating experiment groups, check that the values provided for the size of each sample group, be they
proportions or absolute sizes, are valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>original_population</strong> (<em>pd.DataFrame</em>) – The total dataset from which samples will be drawn.</p></li>
<li><p><strong>sample_groups</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>] or </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – Keys: The names of each sample group
Values: How big they should be.</p></li>
<li><p><strong>size_type</strong> (<em>str 'proportion'</em><em>, </em><em>'absolute'</em>) – Whether the sizes reflect ‘proportion’ or their ‘absolute’ size.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the proportions do not adhere to 0 &lt; proportion &lt; 1.</p></li>
<li><p><strong>ValueError</strong> – If the proportions sum up to more than 1.</p></li>
<li><p><strong>ValueError</strong> – If the absolute sizes sum up to more than the size of the original population.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ds_utils.hypothesis_testing.evaluation">
<span id="evaluation"></span><h4>evaluation<a class="headerlink" href="#module-ds_utils.hypothesis_testing.evaluation" title="Permalink to this headline">¶</a></h4>
<p>Analyse the outcome of an experiment and test for significance.</p>
<dl class="py function">
<dt id="ds_utils.hypothesis_testing.evaluation.parametric_significance_test_on_raw_observations">
<code class="sig-name descname">parametric_significance_test_on_raw_observations</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">group_1_observations</span><span class="p">:</span> <span class="n">numpy.ndarray</span></em>, <em class="sig-param"><span class="n">group_2_observations</span><span class="p">:</span> <span class="n">numpy.ndarray</span></em>, <em class="sig-param"><span class="n">measurement_type</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">alternative_hypothesis</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'two-sided'</span></em>, <em class="sig-param"><span class="n">significance_level</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>float<span class="p">, </span>float<span class="p">]</span><a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/evaluation.html#parametric_significance_test_on_raw_observations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.evaluation.parametric_significance_test_on_raw_observations" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests for a significant difference between the observations recorded for two experimental groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_1_observations</strong> (<em>numpy array_like</em>) – Observations for specific group in the experiment.</p></li>
<li><p><strong>group_2_observations</strong> (<em>numpy array_like</em>) – Observations for other group in the experiment which group_1 will be compared against.</p></li>
<li><p><strong>measurement_type</strong> (<em>str 'proportion'</em><em>, </em><em>'mean'</em>) – Whether the metric is a proportion (e.g. % conversion rate) or mean (e.g. average spend).</p></li>
<li><p><strong>alternative_hypothesis</strong> (<em>str 'two-sided'</em><em> (</em><em>default</em><em>)</em><em>, </em><em>'larger'</em><em>, </em><em>'smaller'</em>) – Whether you are running a ‘two-sided’ test, or checking whether the new metric will be ‘smaller’ or ‘larger’.
‘two-sided’ is generally recommended because we do not know in advance whether the change in our experiment
will yield positive or negative results.</p></li>
<li><p><strong>significance_level</strong> (<em>float in interval</em><em> (</em><em>0</em><em>,</em><em>1</em><em>) </em><em>(</em><em>default is 0.05</em><em>)</em>) – The significance level/probability of a type I error, i.e. likelihood of a false positive (incorrectly rejecting
the Null Hypothesis when it is in fact true). Default value of 5% is commonly used but you should consider what
is appropriate given the business context.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(1st value) p-value, i.e. the probability of obtaining results as extreme as the observed result.
(2nd value) test-statistic, which applies to z-test when measuring proportions, and t-test for means.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[float, float]</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If <cite>significance_level</cite> does not adhere to 0 &lt; significance_level &lt; 1.</p></li>
<li><p><strong>ValueError</strong> – If the experiment metric is a proportion, but the individual observations are not all represented as 0 or 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ds_utils.hypothesis_testing.set_up_experiment">
<span id="set-up-experiment"></span><h4>set_up_experiment<a class="headerlink" href="#module-ds_utils.hypothesis_testing.set_up_experiment" title="Permalink to this headline">¶</a></h4>
<p>Helper functions when setting up an experiment.</p>
<dl class="py function">
<dt id="ds_utils.hypothesis_testing.set_up_experiment.calculate_required_sample_size">
<code class="sig-name descname">calculate_required_sample_size</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">baseline_metric_value</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">new_metric_value</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">measurement_type</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">alternative_hypothesis</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'two-sided'</span></em>, <em class="sig-param"><span class="n">power</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">significance_level</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">standard_deviation</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/set_up_experiment.html#calculate_required_sample_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.set_up_experiment.calculate_required_sample_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the required sample size for an experiment given a certain degree of change that we want to confidently
detect.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>baseline_metric_value</strong> (<em>float</em>) – Baseline value that reflects the current metric we are trying to change e.g. the existing retention rate.</p></li>
<li><p><strong>new_metric_value</strong> (<em>float</em>) – The smallest meaningful effect that we wish to be able to detect i.e. at what point do the results become
commercially interesting e.g. 85% retention vs 80% baseline may be the smallest shift which yield a financial
benefit that makes the project worth implementing.</p></li>
<li><p><strong>measurement_type</strong> (<em>str</em><em> (</em><em>must be 'proportion'</em><em> or </em><em>'mean'</em><em>)</em>) – Whether the metric is a proportion (e.g. % conversion rate) or mean (e.g. average spend).</p></li>
<li><p><strong>alternative_hypothesis</strong> (<em>str 'two-sided'</em><em> (</em><em>default</em><em>)</em><em>, </em><em>'larger'</em><em>, </em><em>'smaller'</em>) – Whether you are running a ‘two-sided’ test, or checking whether the new metric will be ‘smaller’ or ‘larger’.
‘two-sided’ is generally recommended because we do not know in advance whether the change in our experiment
will yield positive or negative results.</p></li>
<li><p><strong>power</strong> (<em>float in interval</em><em> (</em><em>0</em><em>,</em><em>1</em><em>) </em><em>(</em><em>default is 0.8</em><em>)</em>) – Probability that the test correctly rejects the Null Hypothesis if the Alternative Hypothesis is true
i.e. likelihood of detecting a shift when it is genuine (one minus the probability of a type II error).
Default value of 80% is commonly used but you should consider what is appropriate given the business context.</p></li>
<li><p><strong>significance_level</strong> (<em>float in interval</em><em> (</em><em>0</em><em>,</em><em>1</em><em>) </em><em>(</em><em>default is 0.05</em><em>)</em>) – The significance level/probability of a type I error, i.e. likelihood of a false positive (incorrectly rejecting
the Null Hypothesis when it is in fact true). Default value of 5% is commonly used but you should consider what
is appropriate given the business context.</p></li>
<li><p><strong>standard_deviation</strong> (<em>float</em><em> (</em><em>default is none</em><em>)</em>) – Standard deviation for the metric being tested. Only needs to be set if <cite>measurement_type</cite> is ‘mean’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Minimum sample size required to satisfy experiment criteria.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – If <cite>measurement_type</cite> is ‘mean’ but no <cite>standard_deviation</cite> provided.</p></li>
<li><p><strong>ValueError</strong> – If <cite>significance_level</cite> or <cite>power</cite> not in range (0,1).</p></li>
<li><p><strong>ValueError</strong> – If <cite>measurement_type</cite> not in [‘proportion’, ‘mean’].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ds_utils.hypothesis_testing.set_up_experiment.create_sample_groups">
<code class="sig-name descname">create_sample_groups</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">original_population</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">sample_groups</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>dict<span class="p">, </span>list<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="reference internal" href="../_modules/ds_utils/hypothesis_testing/set_up_experiment.html#create_sample_groups"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ds_utils.hypothesis_testing.set_up_experiment.create_sample_groups" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly assign records from a population dataset to distinct sample groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>original_population</strong> (<em>pd.DataFrame</em>) – The total dataset from which samples will be drawn.</p></li>
<li><p><strong>sample_groups</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>] or </em><em>dict</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – Can be a dictionary with the name of each sample group, and its size expressed as a proportion of the
population or absolute size in terms of number of records. Or this can be a list of the names of each sample
group, indicating that the population should be split evenly across them.</p></li>
<li><p><strong>original_population</strong> – The total dataset from which samples will be drawn.</p></li>
<li><p><strong>sample_groups</strong> – Keys: The names of each sample group
Values: How big they should be.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Copy of the original dataset, but with an additional column called ‘sample_group’ denoting the group that
each record has been assigned to, and only containing records that have been assigned (e.g. if we took a sample
that is smaller than the population).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pd.DataFrame</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If the values provided for the sizes of each sample group are not all floats (proportions), or all integers
    (absolute sizes).</p></li>
<li><p><strong>ValueError</strong> – If the proportions do not adhere to 0 &lt; proportion &lt; 1.</p></li>
<li><p><strong>ValueError</strong> – If the proportions sum up to more than 1.</p></li>
<li><p><strong>ValueError</strong> – If the absolute sizes sum up to more than the size of the original population.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="sklearn_utils.html" class="btn btn-neutral float-right" title="ds_utils.sklearn_utils" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral float-left" title="Welcome to ds_utils’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Kieran O&#39;Sullivan

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>